# -*- coding: utf-8 -*-
"""task3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F4LdMhWfwqFCrEzy14sBFomHIO4WUh7C
"""

import numpy as np

def beam_search(encoder_output, beam_width, max_length, vocab_size):



    beams = [(0.0, [0])]

    for _ in range(max_length):
        all_candidates = []
        for score, seq in beams:
            if seq[-1] == 1:
                all_candidates.append((score, seq))
                continue


            next_probs = encoder_output(seq)

            for next_token in range(vocab_size):
                candidate = (score - np.log(next_probs[next_token]), seq + [next_token])
                all_candidates.append(candidate)

        ordered = sorted(all_candidates, key=lambda x: x[0])
        beams = ordered[:beam_width]

    return beams

def mock_encoder_output(sequence):

    return np.random.rand(5)

beam_width = 3
max_length = 5
vocab_size = 5

best_sequences = beam_search(mock_encoder_output, beam_width, max_length, vocab_size)
for score, seq in best_sequences:
    print(f"Sequence: {seq}, Score: {-score:.2f}")

